# sonmari
수어 번역 프로그램입니다.

# 프로그램 목적
청각장애인과 수어를 모르는 비장애인은 서로 소통하기가 어렵다. 특히 병원에서 청각장애인이 제대로 진료받지 못하는 사례가 늘고 있는데,
이를 위해 병원에서 쓰는 수어를 번역할 수 있는 어플을 만들기로 했다.
사용자가 카메라렌즈를 통해 직접 수어영상을 촬영하면, 이를 한국어로 번역해주는 것이다.

수어영상을 입력받아 손모양을 인식하고, 이를 번역하여 음성언어로 바꿔준 뒤 출력해준다.
![틀](https://user-images.githubusercontent.com/74365895/101729534-a71f9800-3afb-11eb-8a29-49b4a98d48f5.jpg)

# 필요 기술
cnn과 rnn을 이용해 촬영한 수어영상을 번역하기로 했다. 입력받은 영상을 프레임 단위로 여러개의 영상으로 자른다. 이후 각각의 작은 영상을 cnn을 이용해 특성을 추출해내고, 이 여러개의 시퀀스데이터를 다시 rnn에 입력하여 전체적인 번역결과를 도출하는 것이 번역 파트의 핵심이다.
사용한 신경망의 구조는 다음과 같다.

<img width="334" alt="신경망" src="https://user-images.githubusercontent.com/74365895/101729589-c61e2a00-3afb-11eb-9653-f9ff3c19d05c.png">


# reference
github.com/EvilPort2/Sign-Language


